{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/Yan-Cheng-Hsu/anaconda3/envs/test/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model , Sequential\n",
    "from keras.layers import Input, LSTM , Bidirectional , Dropout , Activation , Dense , Add , GRU\n",
    "from keras.layers import Conv1D , MaxPooling1D , Flatten , AveragePooling1D , concatenate , BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ' 0 , 1 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data....\n",
      "loading data finished.\n"
     ]
    }
   ],
   "source": [
    "print( 'loading data....' )\n",
    "ppg_part1 = np.load( '/data1/Yan-Cheng-Hsu/ppgData/dataperC/ppg_part1.npy' , allow_pickle = True )\n",
    "ppg_part2 = np.load( '/data1/Yan-Cheng-Hsu/ppgData/dataperC/ppg_part2.npy' , allow_pickle = True )\n",
    "ppg_part3 = np.load( '/data1/Yan-Cheng-Hsu/ppgData/dataperC/ppg_part3.npy' , allow_pickle = True )\n",
    "sbp = np.load( '/data1/Yan-Cheng-Hsu/ppgData/dataperC/sbp.npy' , allow_pickle = True )\n",
    "dbp = np.load( '/data1/Yan-Cheng-Hsu/ppgData/dataperC/dbp.npy' , allow_pickle = True )\n",
    "print( 'loading data finished.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessing......\n"
     ]
    }
   ],
   "source": [
    "print('data preprocessing......')\n",
    "ppg_min = 100\n",
    "ppg_max = -100\n",
    "\n",
    "for x in range( len(ppg_part1) ):\n",
    "    for i in range( len(ppg_part1[x]) ):\n",
    "        temp_min = np.min( ppg_part1[x][i] )\n",
    "        temp_max = np.max( ppg_part1[x][i] )\n",
    "        if temp_min < ppg_min:\n",
    "            ppg_min = temp_min\n",
    "        if temp_max > ppg_max:\n",
    "            ppg_max = temp_max\n",
    "for x in range( len(ppg_part2) ):\n",
    "    for i in range( len(ppg_part2[x]) ):\n",
    "        temp_min = np.min( ppg_part2[x][i] )\n",
    "        temp_max = np.max( ppg_part2[x][i] )\n",
    "        if temp_min < ppg_min:\n",
    "            ppg_min = temp_min\n",
    "        if temp_max > ppg_max:\n",
    "            ppg_max = temp_max\n",
    "for x in range( len(ppg_part3) ):\n",
    "    for i in range( len(ppg_part3[x]) ):\n",
    "        temp_min = np.min( ppg_part3[x][i] )\n",
    "        temp_max = np.max( ppg_part3[x][i] )\n",
    "        if temp_min < ppg_min:\n",
    "            ppg_min = temp_min\n",
    "        if temp_max > ppg_max:\n",
    "            ppg_max = temp_max\n",
    "\n",
    "            \n",
    "ppg_part1 = ( ppg_part1 - ppg_min ) / ( ppg_max - ppg_min )\n",
    "ppg_part2 = ( ppg_part2 - ppg_min ) / ( ppg_max - ppg_min )\n",
    "ppg_part3 = ( ppg_part3 - ppg_min ) / ( ppg_max - ppg_min )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range( len(ppg_part1) ):\n",
    "    for i in range( len(ppg_part1[x]) ):\n",
    "        ppg.append( ppg_part1[x][i] )\n",
    "        \n",
    "for x in range( len(ppg_part2) ):\n",
    "    for i in range( len(ppg_part2[x]) ):\n",
    "        ppg.append( ppg_part2[x][i] )\n",
    "for x in range( len(ppg_part3) ):\n",
    "    for i in range( len(ppg_part3[x]) ):\n",
    "        ppg.append( ppg_part3[x][i] )\n",
    "ppg = np.array( ppg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2468014, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a0a1e1d86354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendIndex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mPPG_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppg_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppg_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mPPG_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppg_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppg_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mBP_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbp_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbp_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bp = []\n",
    "\n",
    "for x in range( len(sbp) ):\n",
    "    for i in range( len(sbp[x]) ):\n",
    "        temp = []\n",
    "        temp.append( sbp[x][i] )\n",
    "        temp.append( dbp[x][i] )\n",
    "        temp = np.array( temp )\n",
    "        bp.append( temp )\n",
    "bp = np.array( bp )\n",
    "\n",
    "endIndex = int( len(ppg)*0.8 )\n",
    "ppg_train = ppg[0:endIndex]\n",
    "ppg_test = ppg[endIndex:]\n",
    "bp_train = bp[0:endIndex]\n",
    "bp_test = bp[endIndex:]\n",
    "\n",
    "PPG_train = ppg_train.reshape( len(ppg_train) , 300 , 1 ).astype( float )\n",
    "PPG_test = ppg_test.reshape( len(ppg_test) , 300 , 1 ).astype( float )\n",
    "BP_train = bp_train.reshape( len(bp_train) , 1 , 2 ).astype( float )\n",
    "BP_test = bp_test.reshape( len(bp_test) , 1 , 2 ).astype( float )\n",
    "\n",
    "print('data preprocessing finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( PPG_train.shape )\n",
    "print( PPG_test.shape )\n",
    "print( BP_train.shape )\n",
    "print( BP_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 start\n",
    "Inputshape = ( len(PPG_train[0]) , len(PPG_train[0][0]) )\n",
    "X_input1 = Input( Inputshape )\n",
    "X_CNN1 = Conv1D( 64 , int(len( PPG_train[0] )/4) , border_mode = 'same' , activation = 'relu' )( X_input1 )\n",
    "X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN1 )\n",
    "X_CNN1 = Conv1D( 64 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN1 ) \n",
    "X_CNN1 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN1 )\n",
    "X_CNN1 = Conv1D( 128 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN1 ) \n",
    "X_CNN1 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN1 )\n",
    "X_CNN1 = Dropout(0.25)(X_CNN1)\n",
    "\n",
    "#X_CNN1 = BatchNormalization( X_CNN1 )\n",
    "\n",
    "\n",
    "\n",
    "''''X_input2 = Input( Inputshape )\n",
    "X_CNN2 = Conv1D( 64 , int(len( PPG_train[0] )/2) , border_mode = 'same' , activation = 'relu' )( X_input2 )\n",
    "X_CNN2 = MaxPooling1D( pool_size = 2 )( X_CNN2 )\n",
    "X_CNN2 = Conv1D( 64 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN2 ) \n",
    "X_CNN2 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN2 )\n",
    "X_CNN2 = Conv1D( 128 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN2 ) \n",
    "X_CNN2 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN2 )\n",
    "X_CNN2 = Dropout(0.25)(X_CNN2)\n",
    "X_CNN2 = BatchNormalization( X_CNN2 )\n",
    "\n",
    "X_input3 = Input( Inputshape )\n",
    "X_CNN3 = Conv1D( 64 , int(len( PPG_train[0] )/2) , border_mode = 'same' , activation = 'relu' )( X_input3 )\n",
    "X_CNN3 = MaxPooling1D( pool_size = 2 )( X_CNN3 )\n",
    "X_CNN3 = Conv1D( 64 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN3 ) \n",
    "X_CNN3 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN3 )\n",
    "X_CNN3 = Conv1D( 128 , 4 , border_mode = 'same' , activation = 'relu' )( X_CNN3 ) \n",
    "X_CNN3 = X_CNN1 = MaxPooling1D( pool_size = 2 )( X_CNN3 )\n",
    "X_CNN3 = Dropout(0.25)(X_CNN3)\n",
    "X_CNN3 = BatchNormalization( X_CNN3 )\n",
    "\n",
    "\n",
    "X_CNN = concatenate( [ X_CNN1 , X_CNN2 , X_CNN3 ] )'''\n",
    "\n",
    "\n",
    "LayerUnits = 1024*2\n",
    "''''X0 = Bidirectional(GRU(LayerUnits, return_sequences=True), merge_mode='concat')(X_CNN1)\n",
    "X0 = Dropout(0.2)(X0)\n",
    "X0 = Activation('relu')(X0)\n",
    "\n",
    "X = GRU(LayerUnits, return_sequences=True)(X0)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X1 = GRU(LayerUnits, return_sequences=True)(X)\n",
    "X1 = Dropout(0.2)(X1)\n",
    "X1 = Activation('relu')(X1)\n",
    "\n",
    "X2 = concatenate([X, X1])\n",
    "X2 = GRU(LayerUnits, return_sequences=True)(X2)\n",
    "X2 = Dropout(0.2)(X2)\n",
    "X2 = Activation('relu')(X2)\n",
    "\n",
    "\n",
    "X3 = concatenate( [X2,X] )\n",
    "X3 = GRU(LayerUnits, return_sequences=True)(X3)\n",
    "X3 = Dropout(0.2)(X3)\n",
    "X3 = Activation('relu')(X3)'''\n",
    "\n",
    "X = Dense(LayerUnits , activation = 'relu')(X_CNN1)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(LayerUnits , activation = 'relu')(X_CNN1)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(LayerUnits , activation = 'relu')(X_CNN1)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(LayerUnits , activation = 'relu')(X_CNN1)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(LayerUnits , activation = 'relu')(X_CNN1)\n",
    "X = Dropout(0.2)(X)\n",
    "\n",
    "X_output = Dense(2)(X)\n",
    "\n",
    "GRUModel = Model( inputs = X_input1  , outputs = X_output )\n",
    "# Compiling\n",
    "GRUModel.compile(optimizer = 'adam', loss = rmse_loss )\n",
    "GRUModel.summary()\n",
    "GRUModel.fit( PPG_train , BP_train, validation_split = 0.1 , epochs = 100 , batch_size = 2048)\n",
    "\n",
    "path = '/data1/Yan-Cheng-Hsu/CNNModel/model_20200516/CNN_model_20200516_1.h5'\n",
    "print( 'saving model.....' )\n",
    "GRUModel.save( path )\n",
    "print( 'finish saving model.....' )\n",
    "\n",
    "\n",
    "\n",
    "print( 'Training set : '  ,  GRUModel.evaluate( PPG_test , BP_test ) )\n",
    "print( 'Testing set :' , GRUModel.evaluate( PPG_test , BP_test ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
